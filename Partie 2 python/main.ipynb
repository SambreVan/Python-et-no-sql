{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download du livre en txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page web téléchargée avec succès dans livres.txt\n"
     ]
    }
   ],
   "source": [
    "def Download(url, nom_fichier_sortie):\n",
    "    reponse = requests.get(url)\n",
    "    if reponse.status_code == 200:\n",
    "        with open(nom_fichier_sortie, 'w', encoding='utf-8') as fichier:\n",
    "            fichier.write(reponse.text)\n",
    "        print(f\"Page web téléchargée avec succès dans {nom_fichier_sortie}\")\n",
    "    else:\n",
    "        print(f\"Échec du téléchargement. Statut HTTP : {reponse.status_code}\")\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
    "nom_fichier_sortie = \"livres.txt\"\n",
    "Download(url, nom_fichier_sortie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lire je txt et faire un json auteur et titre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title_and_author(text):\n",
    "    title_pattern = r\"The Project Gutenberg eBook of (.+?)\\n\"\n",
    "    author_pattern = r\"by\\s+([^\\n]+)\"\n",
    "\n",
    "    title_match = re.search(title_pattern, text)\n",
    "    author_match = re.search(author_pattern, text)\n",
    "\n",
    "    title = title_match.group(1).strip() if title_match else \"Title not found\"\n",
    "    author = author_match.group(1).strip() if author_match else \"Author not found\"\n",
    "\n",
    "    return title, author\n",
    "\n",
    "def extract_title_and_author_with_encoding(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        #problème encodage à gérer\n",
    "        with open(file_path, 'r', encoding='cp1252') as file:\n",
    "            text = file.read()\n",
    "\n",
    "    return extract_title_and_author(text)\n",
    "\n",
    "def create_json_with_title_and_author(file_path):\n",
    "    title, author = extract_title_and_author_with_encoding(file_path)\n",
    "    book_info = {\n",
    "        \"title\": title,\n",
    "        \"author\": author\n",
    "    }\n",
    "    json_file_path = file_path.replace('.txt', '.json')\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(book_info, json_file, indent=4)\n",
    "\n",
    "    return json_file_path\n",
    "\n",
    "file_path = 'livres.txt'\n",
    "json_file_path = create_json_with_title_and_author(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extraire le chapitre 1 et en faire un txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_chapter_one(input_file_path, output_file_path):\n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        start_index = content.find(\"Chapter I.]\")\n",
    "        end_index = content.find(\"[Illustration: M^{r.} & M^{rs.} Bennet\")\n",
    "\n",
    "        if start_index == -1 or end_index == -1:\n",
    "            return \"Chapter markers not found.\"\n",
    "\n",
    "        # Extraire le contenu entre les deux index\n",
    "        chapter_one_content = content[start_index:end_index]\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(chapter_one_content)\n",
    "        \n",
    "        return f\"Chapter I extracted to {output_file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "    \n",
    "extract_and_save_chapter_one('livres.txt', 'chapter_one.txt')\n",
    "chapter_path = 'chapter_one.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compter les mots par paragraphes, un peu galère car c'est des discussions donc j'ai simulé des paragraphes grace aux sauts de lignes de minium 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombres de mots par paragraphe (du plus long au plus court) :\n",
      "[18, 17, 16, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 12, 12, 12, 12, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 10, 10, 10, 9, 9, 8, 8, 7, 7, 7, 7, 7, 6, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Nombre de paragraphes par tranche de dix mots :\n",
      "0 mots : 57 paragraphes\n",
      "10 mots : 50 paragraphes\n",
      "20 mots : 15 paragraphes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def count_sort_paragraphs_and_group_by_dizaine(chapter_path):\n",
    "    with open(chapter_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "\n",
    "    word_counts = []\n",
    "    for para in paragraphs:\n",
    "        word_count = len(para.split())\n",
    "        word_counts.append(word_count)\n",
    "\n",
    "    word_counts.sort(reverse=True)\n",
    "\n",
    "    print(\"Nombres de mots par paragraphe (du plus long au plus court) :\")\n",
    "    print(word_counts)\n",
    "\n",
    "    paragraph_count_by_dizaine = {}\n",
    "    for count in word_counts:\n",
    "        rounded_count = round(count / 10) * 10\n",
    "        if rounded_count in paragraph_count_by_dizaine:\n",
    "            paragraph_count_by_dizaine[rounded_count] += 1\n",
    "        else:\n",
    "            paragraph_count_by_dizaine[rounded_count] = 1\n",
    "\n",
    "    print(\"\\nNombre de paragraphes par tranche de dix mots :\")\n",
    "    for dizaine in sorted(paragraph_count_by_dizaine):\n",
    "        print(f\"{dizaine} mots : {paragraph_count_by_dizaine[dizaine]} paragraphes\")\n",
    "\n",
    "chapter_path = 'chapter_one.txt'\n",
    "print(count_sort_paragraphs_and_group_by_dizaine(chapter_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "là je fais le graph en enlevant les erreurs ou y'a 0 mots par paragphes et je le sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_non_zero_paragraph_lengths(chapter_path):\n",
    "    with open(chapter_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "\n",
    "    word_counts = [len(para.split()) for para in paragraphs if len(para.split()) > 0]\n",
    "\n",
    "    length_counts = {}\n",
    "    for count in word_counts:\n",
    "        if count in length_counts:\n",
    "            length_counts[count] += 1\n",
    "        else:\n",
    "            length_counts[count] = 1\n",
    "\n",
    "    sorted_lengths = sorted(length_counts.keys())\n",
    "    sorted_counts = [length_counts[length] for length in sorted_lengths]\n",
    "\n",
    "    plt.bar(sorted_lengths, sorted_counts)\n",
    "    plt.xlabel('Longueur des paragraphes (nombre de mots)')\n",
    "    plt.ylabel('Nombre d\\'occurrences')\n",
    "    plt.title('Distribution de la longueur des paragraphes')\n",
    "    plt.savefig(output_filename)\n",
    "    plt.close()\n",
    "\n",
    "output_filename = 'data.png'\n",
    "plot_non_zero_paragraph_lengths(chapter_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "télécharger et redimensionner l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_resize_image(url, scaling_factor=0.2, filename='img.png'):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "\n",
    "            with Image.open(filename) as img:\n",
    "                new_size = (int(img.width * scaling_factor), int(img.height * scaling_factor))\n",
    "                resized_img = img.resize(new_size)\n",
    "                resized_img.save(filename)\n",
    "\n",
    "            return f\"L'image a été téléchargée, redimensionnée à 20% de sa taille originale, et sauvegardée sous le nom '{filename}'.\"\n",
    "        else:\n",
    "            return \"Erreur lors du téléchargement de l'image : la requête a échoué.\"\n",
    "    except Exception as e:\n",
    "        return f\"Une erreur est survenue lors du téléchargement ou de la redimension de l'image : {e}\"\n",
    "    \n",
    "result = download_and_resize_image('https://m.media-amazon.com/images/M/MV5BMTA1NDQ3NTcyOTNeQTJeQWpwZ15BbWU3MDA0MzA4MzE@._V1_.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collage de mon coeur en noir et blanc sur l'image 1\n",
    "je les converts sinon ça passe pas et je génère une nouvelle image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = Image.open('img.png')\n",
    "imagecollage = Image.open('hearth.png')\n",
    "\n",
    "imagebase=imagebase.convert(\"RGBA\")\n",
    "imagecollage=imagecollage.convert(\"RGBA\")\n",
    "\n",
    "imagebase.alpha_composite(imagecollage, dest=(25,25))\n",
    "imagebase.save('collage.png')\n",
    "imagebase.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j'utilise le json et l'image ainsi que des choses écrites directement dans le code pour générer mon document word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('livres.json', 'r') as file:\n",
    "    book_info = json.load(file)\n",
    "\n",
    "doc = Document()\n",
    "\n",
    "report_author = \"Sambre Vandercoilden\"\n",
    "\n",
    "title_para = doc.add_paragraph()\n",
    "title_run = title_para.add_run(book_info['title'])\n",
    "title_run.font.size = Pt(24)\n",
    "title_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "author_para = doc.add_paragraph(f\"Author: {book_info['author']}\")\n",
    "author_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "doc.add_picture('collage.png', width=Inches(3))\n",
    "doc.paragraphs[-1].alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "doc.add_page_break()\n",
    "\n",
    "doc.add_paragraph(\"La campagne anglaise à la fin du XVIIIe siècle. Mrs. Bennet et son mari sont ravis d'apprendre qu'un jeune homme fortuné - et célibataire - vient de s'installer dans le manoir voisin. Désargentés, les Bennet se font fort de marier l'une de leurs cinq filles au nouvel arrivant... Ce dernier ne tarde pas à s'éprendre de la belle Jane, l'aînée de la famille, lors d'un bal de campagne. \\nGraphique montrant la répartition du nombre de mots dans le premier chapitre du livre. \\nLe maximum étant de 18 et le minimum de 1 parmis 82 paragraphes. \\nL'image de couverture du livre est également incluse.\")\n",
    "\n",
    "image_path = 'data.png'\n",
    "with Image.open(image_path) as img:\n",
    "    original_width, original_height = img.size\n",
    "    new_width, new_height = original_width * 1.1, original_height * 1.1\n",
    "\n",
    "width_in_inches = new_width / 96\n",
    "height_in_inches = new_height / 96\n",
    "\n",
    "doc.add_picture(image_path, width=Inches(width_in_inches), height=Inches(height_in_inches))\n",
    "doc.paragraphs[-1].alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "report_author_para = doc.add_paragraph(report_author)\n",
    "report_author_para.alignment = WD_PARAGRAPH_ALIGNMENT.RIGHT\n",
    "\n",
    "# ON SAVE ET C EST FINI\n",
    "doc.save('pride_and_prejudice_report.docx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
